{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "---\n",
    "import the libraries and intialize the parameters for this workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket() # or use your own custom bucket name\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "base_job_prefix = 'frame-processor'\n",
    "\n",
    "pipeline_name = f\"{base_job_prefix}-pipeline\"  # SageMaker Pipeline name\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz'\n",
    "!tar xopf CUB_200_2011.tgz\n",
    "!rm CUB_200_2011.tgz\n",
    "\n",
    "s3_raw_data = f's3://{bucket}/{prefix}/full/data'\n",
    "!aws s3 cp --recursive ./CUB_200_2011 $s3_raw_data\n",
    "\n",
    "!rm -rf ./CUB_200_2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a Training Pipeline\n",
    "---\n",
    "\n",
    "The pipelines configured includes python package under SageMaker Pipelines together with the defined code for preprocessing, training, and model evaluation to automate the model training. It is easy to use such that you can simple drop in whatever input data for image classification you want and have it train a model automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Script\n",
    "\n",
    "---\n",
    "Here is teh preprocessing script. we are using script processor from sageMaker processing to split the data into train, valid, and test channels, and then build the TFRecord file for pipe mode training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize 'pipeline/preprocess.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value='s3://sagemaker-us-west-2-987720697751/frame-processor/full/data'\n",
    ")\n",
    "\n",
    "input_annotation = ParameterString(\n",
    "    name=\"AnnotationFileName\",\n",
    "    default_value=\"classes.txt\"\n",
    ")\n",
    "\n",
    "# This is a large dataset, we are only going to train a subset of the classes\n",
    "class_selection = ParameterString(\n",
    "    name=\"ClassSelection\",\n",
    "    default_value=\"13, 17, 35, 36, 47, 68, 73, 87\" #If use the mini dataset, please make sure to use the class index with the available list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  frame-processor-2022-06-11-15-04-45-688\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': ParameterString(name='InputDataUrl', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-us-west-2-987720697751/frame-processor/full/data'), 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor-2022-06-11-15-04-45-688/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor-2022-06-11-15-04-45-688/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor/outputs/train', 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor/outputs/valid', 'LocalPath': '/opt/ml/processing/output/valid', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-3', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor/outputs/test', 'LocalPath': '/opt/ml/processing/output/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-4', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/frame-processor/outputs/manifest', 'LocalPath': '/opt/ml/processing/output/manifest', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py:197: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn import SKLearn, SKLearnProcessor\n",
    "\n",
    "from sagemaker.processing import FrameworkProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "import uuid\n",
    "\n",
    "# SKlearnProcessor for preprocessing\n",
    "\n",
    "session = PipelineSession()\n",
    "\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "                                    estimator_cls=SKLearn,\n",
    "                                    framework_version='0.23-1',\n",
    "                                    base_job_name = base_job_prefix,\n",
    "                                    command=['python3'],\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    sagemaker_session = session)\n",
    "\n",
    "\n",
    "output_s3_uri = f's3://{default_bucket}/{base_job_prefix}/outputs'\n",
    "\n",
    "step_args = sklearn_processor.run(\n",
    "            code='preprocessing.py',\n",
    "            arguments=[\"--classes\", class_selection, \n",
    "                       \"--input-data\", input_annotation],\n",
    "            inputs=[ProcessingInput(source=input_data, \n",
    "                    destination=\"/opt/ml/processing/input\")],\n",
    "            outputs=[\n",
    "                    ProcessingOutput(source=\"/opt/ml/processing/output/train\", destination = output_s3_uri +'/train'),\n",
    "                    ProcessingOutput(source=\"/opt/ml/processing/output/valid\", destination = output_s3_uri +'/valid'),\n",
    "                    ProcessingOutput(source=\"/opt/ml/processing/output/test\", destination = output_s3_uri +'/test'),\n",
    "                    ProcessingOutput(source=\"/opt/ml/processing/output/manifest\", destination = output_s3_uri +'/manifest'),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"FrameworkProcessor\",  # choose any name\n",
    "    step_args=step_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        input_annotation,\n",
    "        class_selection\n",
    "    ],\n",
    "    steps=[step_process],\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "# Submit pipline\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Execute pipeline using the default parameters.\n",
    "execution = pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
